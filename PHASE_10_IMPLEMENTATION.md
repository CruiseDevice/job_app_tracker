# Phase 10: Polish & Optimization - Implementation Guide

## Overview

Phase 10 implements comprehensive monitoring, cost tracking, explainability, and error handling systems for the multi-agent job application tracker. This phase focuses on production-readiness, observability, and reliability.

## Table of Contents

1. [Features Implemented](#features-implemented)
2. [Architecture](#architecture)
3. [Performance Monitoring](#performance-monitoring)
4. [Cost Tracking](#cost-tracking)
5. [Decision Explainability](#decision-explainability)
6. [Error Handling & Failsafe](#error-handling--failsafe)
7. [API Endpoints](#api-endpoints)
8. [Frontend Components](#frontend-components)
9. [Usage Examples](#usage-examples)
10. [Configuration](#configuration)
11. [Best Practices](#best-practices)

---

## Features Implemented

### ‚úÖ 1. Agent Performance Monitoring and Logging

**Location:** `backend/agents_framework/monitoring/`

- **Performance Monitor** (`performance_monitor.py`)
  - Real-time execution tracking
  - Token usage monitoring
  - Response time analysis
  - Success/failure rate tracking
  - Historical performance data
  - Performance alerts and thresholds
  - Metrics aggregation and export

- **Structured Logger** (`structured_logger.py`)
  - JSON-formatted logs
  - Request ID tracking
  - Context propagation
  - Log correlation
  - Multiple log levels
  - Performance logging

**Key Features:**
- ‚è±Ô∏è Execution time tracking with millisecond precision
- üìä Aggregated metrics over configurable time periods
- üîî Automatic performance alerts based on thresholds
- üíæ Exportable metrics in JSON format
- üîç Request correlation across distributed operations

### ‚úÖ 2. Cost Tracking for Agent API Calls

**Location:** `backend/agents_framework/monitoring/cost_tracker.py`

- Accurate token usage tracking (input/output separated)
- Multi-model pricing support (GPT-4O, GPT-4O-Mini, GPT-4-Turbo, GPT-3.5-Turbo)
- Per-agent cost analytics
- Budget monitoring with alerts
- Cost optimization recommendations
- Model comparison and breakdowns

**Pricing (per 1M tokens):**
- **GPT-4O**: $2.50 input / $10.00 output
- **GPT-4O-Mini**: $0.15 input / $0.60 output
- **GPT-4-Turbo**: $10.00 input / $30.00 output
- **GPT-3.5-Turbo**: $0.50 input / $1.50 output

**Key Features:**
- üí∞ Real-time cost calculation
- üìà Cost trending and forecasting
- üéØ Budget limits with automatic alerts
- üí° Smart recommendations for cost optimization
- üìä Model-specific cost breakdowns

### ‚úÖ 3. Agent Decision Explanation System

**Location:** `backend/agents_framework/explainability/`

- **Decision Explainer** (`decision_explainer.py`)
  - Reasoning step tracking
  - Tool usage justification
  - Confidence scoring
  - Alternative options documentation
  - Key factors identification
  - Assumptions and limitations tracking

- **Explanation Formatter** (`explanation_formatter.py`)
  - Multiple output formats (Markdown, HTML, Plain Text, JSON)
  - Professional formatting
  - Rich visualization support
  - Exportable explanations

**Explanation Components:**
1. **Reasoning Steps**: Step-by-step decision process
2. **Tool Usage**: Why each tool was used and outcomes
3. **Alternatives Considered**: Other options evaluated
4. **Key Factors**: Main decision influencers
5. **Assumptions**: What was assumed
6. **Limitations**: Known constraints
7. **Confidence Score**: Decision confidence (0-100%)

### ‚úÖ 4. Agent Failsafe and Error Handling

**Location:** `backend/agents_framework/failsafe/`

- **Retry Handler** (`retry_handler.py`)
  - Configurable retry policies
  - Multiple backoff strategies (exponential, linear, fixed, jitter)
  - Exception filtering
  - Timeout support
  - Retry statistics

- **Circuit Breaker** (`circuit_breaker.py`)
  - Three-state circuit (closed, open, half-open)
  - Automatic failure detection
  - Self-healing with periodic retries
  - Configurable thresholds
  - Circuit state monitoring

- **Error Handler** (`error_handler.py`)
  - Error classification (10+ categories)
  - Severity assessment (low, medium, high, critical)
  - Recovery strategy selection
  - Error history tracking
  - Graceful degradation support

**Error Categories:**
- Network errors
- Timeout errors
- Rate limiting
- Authentication failures
- Validation errors
- Resource errors
- Configuration errors
- External service failures

**Recovery Strategies:**
- Retry with backoff
- Fallback to defaults
- Skip and continue
- Escalate to admin
- Fail fast
- Graceful degradation

### ‚úÖ 5. Agent Configuration and Settings UI

**Location:** `frontend/src/components/Agents/MonitoringDashboard.tsx`

- Real-time monitoring dashboard
- Performance metrics visualization
- Cost analytics display
- Alert management interface
- Period selection (1 hour, 24 hours, 1 week)
- Auto-refresh every 30 seconds
- Agent-specific detailed views

**Dashboard Features:**
- üìä Summary cards (total cost, executions, success rate, avg response time)
- ‚ö†Ô∏è Active alerts section
- ü§ñ Per-agent performance cards
- üí∞ Cost breakdown by agent and model
- üî¢ Token usage statistics
- ‚ùå Recent error display

### ‚úÖ 6. Comprehensive Documentation

This document plus:
- Inline code documentation
- API endpoint documentation
- Usage examples
- Best practices guide

### ‚úÖ 7. Integration with BaseAgent

All monitoring, cost tracking, and explainability features are automatically integrated into the `BaseAgent` class, meaning all agents inherit these capabilities without additional code.

---

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        FastAPI Backend                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              Agent Framework Layer                    ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  BaseAgent ‚îÇ  ‚îÇ Monitoring ‚îÇ  ‚îÇ Explainer  ‚îÇ      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ            ‚îÇ‚îÄ‚îÄ‚îÇ   System   ‚îÇ‚îÄ‚îÄ‚îÇ   System   ‚îÇ      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ              ‚îÇ                ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ              ‚îÇ                ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   Failsafe  ‚îÇ  ‚îÇ    Cost    ‚îÇ  ‚îÇ Performance‚îÇ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   Handler   ‚îÇ  ‚îÇ  Tracker   ‚îÇ  ‚îÇ  Monitor   ‚îÇ    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                           ‚îÇ                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                 API Routes Layer                       ‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ  /api/monitoring/*  ‚îÇ  /api/agents/*  ‚îÇ  /api/costs/* ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚îÇ REST API / WebSocket
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      React Frontend                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ            Monitoring Dashboard Component                 ‚îÇ ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Performance Metrics   ‚Ä¢ Cost Analytics                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Alert Management      ‚Ä¢ Agent Configuration           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Real-time Updates     ‚Ä¢ Export Functionality          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Performance Monitoring

### Usage in Agent Code

The monitoring system is automatically integrated into `BaseAgent`. Every agent execution is tracked:

```python
from agents_framework.core.base_agent import BaseAgent, AgentConfig

# Monitoring happens automatically
agent = BaseAgent(AgentConfig(name="MyAgent"))
response = await agent.run("Do something")  # Automatically tracked!
```

### Manual Monitoring

For custom monitoring:

```python
from agents_framework.monitoring import global_performance_monitor

# Start tracking
global_performance_monitor.start_execution(
    agent_name="CustomAgent",
    execution_id="unique-id",
    context={"user": "john@example.com"}
)

# ... do work ...

# End tracking
metrics = global_performance_monitor.end_execution(
    execution_id="unique-id",
    success=True,
    tokens_used=1500,
    cost=0.0025,
    tool_calls=3
)
```

### Retrieving Metrics

```python
# Get aggregated metrics for last 24 hours
metrics = global_performance_monitor.get_aggregated_metrics("EmailAnalystAgent", period_hours=24)

print(f"Success Rate: {metrics.success_rate}%")
print(f"Average Time: {metrics.avg_execution_time}s")
print(f"Total Cost: ${metrics.total_cost}")

# Get all agents summary
summary = global_performance_monitor.get_all_agents_summary(period_hours=24)

# Get performance alerts
alerts = global_performance_monitor.get_performance_alerts({
    'max_error_rate': 10.0,
    'max_avg_execution_time': 30.0,
    'max_avg_cost': 0.50
})
```

### Exporting Metrics

```python
# Export as JSON
json_data = global_performance_monitor.export_metrics(
    agent_name="EmailAnalystAgent",
    filepath="metrics_export.json"
)
```

---

## Cost Tracking

### Automatic Cost Tracking

Costs are automatically tracked in `BaseAgent`:

```python
# Cost tracking happens automatically!
agent = BaseAgent(AgentConfig(
    name="MyAgent",
    model="gpt-4o-mini"  # Cost calculated based on model
))
response = await agent.run("Analyze this email")
```

### Manual Cost Tracking

```python
from agents_framework.monitoring import global_cost_tracker

# Track usage
usage = global_cost_tracker.track_usage(
    agent_name="CustomAgent",
    model="gpt-4o-mini",
    input_tokens=1000,
    output_tokens=500
)

print(f"Cost: ${usage.total_cost}")
```

### Budget Management

```python
# Set daily budget
global_cost_tracker.daily_budget = 10.00  # $10 per day

# Check budget status
status = global_cost_tracker.check_budget_status()
if status['budget_used_percent'] > 90:
    print("Warning: 90% of budget used!")

# Get cost summary
summary = global_cost_tracker.get_agent_summary("EmailAnalystAgent", period_hours=24)
print(f"Total cost: ${summary.total_cost}")
print(f"Average per call: ${summary.avg_cost_per_call}")
```

### Cost Optimization

```python
# Get optimization tips
tips = global_cost_tracker.get_cost_optimization_tips()
for tip in tips:
    print(f"{tip['agent']}: {tip['message']}")
    if 'potential_savings' in tip:
        print(f"  Potential savings: {tip['potential_savings']}")
```

---

## Decision Explainability

### Creating Explanations

```python
from agents_framework.explainability import (
    global_decision_explainer,
    ReasoningType
)

# Create explanation
explanation = global_decision_explainer.create_explanation(
    agent_name="EmailAnalystAgent",
    execution_id="exec-123",
    decision="Email classified as job offer with high urgency",
    confidence_score=0.92
)

# Add reasoning steps
global_decision_explainer.add_reasoning_step(
    execution_id="exec-123",
    reasoning_type=ReasoningType.OBSERVATION,
    content="Email contains keywords: 'offer', 'salary', 'start date'"
)

global_decision_explainer.add_reasoning_step(
    execution_id="exec-123",
    reasoning_type=ReasoningType.THOUGHT,
    content="Multiple positive indicators suggest this is a job offer"
)

global_decision_explainer.add_reasoning_step(
    execution_id="exec-123",
    reasoning_type=ReasoningType.DECISION,
    content="Classified as job offer with urgent flag"
)

# Add tool usage
global_decision_explainer.add_tool_usage(
    execution_id="exec-123",
    tool_name="sentiment_analyzer",
    reason="To determine tone and urgency of email",
    inputs={"text": "email body"},
    expected_outcome="Positive sentiment with high urgency",
    actual_outcome="Positive (0.85), Urgent (0.92)",
    success=True
)

# Add alternatives
global_decision_explainer.add_alternative(
    execution_id="exec-123",
    description="Classify as informational email",
    pros=["Safer default classification"],
    cons=["Might miss time-sensitive opportunities"],
    confidence=0.35,
    reason_not_chosen="Strong indicators suggest job offer, not general info"
)

# Add key factors, assumptions, limitations
global_decision_explainer.add_key_factors("exec-123", [
    "Presence of salary information",
    "Explicit job title mentioned",
    "Sender from HR department"
])

global_decision_explainer.add_assumptions("exec-123", [
    "Email sender domain is legitimate",
    "Email content is in English"
])

global_decision_explainer.add_limitations("exec-123", [
    "Cannot verify authenticity of offer",
    "Limited context about previous communications"
])
```

### Formatting Explanations

```python
from agents_framework.explainability import ExplanationFormatter, ExplanationFormat

explanation = global_decision_explainer.get_explanation("exec-123")

# Format as Markdown
markdown = ExplanationFormatter.format(explanation, ExplanationFormat.MARKDOWN)

# Format as HTML
html = ExplanationFormatter.format(explanation, ExplanationFormat.HTML)

# Format as plain text
text = ExplanationFormatter.format(explanation, ExplanationFormat.PLAIN_TEXT)

# Format as JSON
json_str = ExplanationFormatter.format(explanation, ExplanationFormat.JSON)
```

### Generating Summaries

```python
# Generate human-readable summary
summary = global_decision_explainer.generate_summary("exec-123")
print(summary)
```

---

## Error Handling & Failsafe

### Retry Handler

```python
from agents_framework.failsafe import RetryHandler, RetryPolicy, BackoffStrategy

# Create retry policy
policy = RetryPolicy(
    max_retries=3,
    initial_delay=1.0,
    max_delay=60.0,
    backoff_strategy=BackoffStrategy.EXPONENTIAL_JITTER,
    retry_on_exceptions=[ConnectionError, TimeoutError]
)

# Use retry handler
retry_handler = RetryHandler(policy)

# Async function
async def risky_operation():
    # Might fail
    pass

result = await retry_handler.execute_async(risky_operation)

# Or use decorator
from agents_framework.failsafe import with_retry

@with_retry(policy=policy)
async def my_function():
    # Automatically retried on failure
    pass
```

### Circuit Breaker

```python
from agents_framework.failsafe import (
    CircuitBreaker,
    CircuitBreakerConfig,
    with_circuit_breaker
)

# Create circuit breaker
config = CircuitBreakerConfig(
    failure_threshold=5,  # Open after 5 failures
    success_threshold=2,  # Close after 2 successes
    timeout=60.0  # Try again after 60 seconds
)

circuit = CircuitBreaker("external_api", config)

# Use circuit breaker
async def call_external_api():
    # Might fail
    pass

try:
    result = await circuit.execute_async(call_external_api)
except CircuitBreakerError:
    print("Circuit is open, service unavailable")

# Or use decorator
@with_circuit_breaker("external_api", config)
async def protected_function():
    # Protected by circuit breaker
    pass

# Check circuit state
print(f"Circuit state: {circuit.get_state()}")
stats = circuit.get_stats()
```

### Error Handler

```python
from agents_framework.failsafe import global_error_handler

try:
    # Some operation
    risky_function()
except Exception as e:
    error_info = global_error_handler.handle_error(
        exception=e,
        context={"operation": "email_processing", "user": "john@example.com"}
    )

    print(f"Error ID: {error_info.error_id}")
    print(f"Severity: {error_info.severity}")
    print(f"Category: {error_info.category}")
    print(f"Recovery Strategy: {error_info.recovery_strategy}")

# Get error statistics
stats = global_error_handler.get_error_stats()
print(f"Total errors: {stats['total_errors']}")
print(f"Recovery rate: {stats['recovery_rate']}%")

# Export error history
json_data = global_error_handler.export_errors("errors_export.json")
```

---

## API Endpoints

### Performance Monitoring Endpoints

```
GET  /api/monitoring/performance/agents?period_hours=24
     ‚Üí Get performance summary for all agents

GET  /api/monitoring/performance/agents/{agent_name}?period_hours=24
     ‚Üí Get performance metrics for specific agent

GET  /api/monitoring/performance/agents/{agent_name}/raw?limit=100
     ‚Üí Get raw metrics data

GET  /api/monitoring/performance/alerts?max_error_rate=10&max_avg_execution_time=30
     ‚Üí Get performance alerts

GET  /api/monitoring/health
     ‚Üí Get monitoring system health status

GET  /api/monitoring/export/metrics?agent_name=EmailAnalystAgent
     ‚Üí Export metrics as JSON
```

### Cost Tracking Endpoints

```
GET  /api/monitoring/costs/agents?period_hours=24
     ‚Üí Get cost summary for all agents

GET  /api/monitoring/costs/agents/{agent_name}?period_hours=24
     ‚Üí Get cost summary for specific agent

GET  /api/monitoring/costs/total?period_hours=24
     ‚Üí Get total costs across all agents

GET  /api/monitoring/costs/budget/status
     ‚Üí Get budget status and alerts

GET  /api/monitoring/costs/optimization/tips
     ‚Üí Get cost optimization recommendations

POST /api/monitoring/costs/budget/set?budget=10.00
     ‚Üí Set daily budget limit

GET  /api/monitoring/export/costs
     ‚Üí Export cost report as JSON
```

### Example API Calls

```bash
# Get performance metrics
curl "http://localhost:8000/api/monitoring/performance/agents?period_hours=24"

# Get cost summary
curl "http://localhost:8000/api/monitoring/costs/agents/EmailAnalystAgent?period_hours=24"

# Set budget
curl -X POST "http://localhost:8000/api/monitoring/costs/budget/set?budget=15.00"

# Get optimization tips
curl "http://localhost:8000/api/monitoring/costs/optimization/tips"
```

---

## Frontend Components

### Monitoring Dashboard

Access the monitoring dashboard at: `/agents/monitoring`

**Features:**
- Real-time performance metrics
- Cost analytics
- Alert management
- Per-agent detailed views
- Configurable time periods
- Auto-refresh
- Export functionality

**Component Usage:**

```tsx
import MonitoringDashboard from './components/Agents/MonitoringDashboard';

function App() {
  return <MonitoringDashboard />;
}
```

---

## Configuration

### Backend Configuration

Edit `backend/config/settings.py`:

```python
class Settings(BaseSettings):
    # Monitoring
    monitoring_enabled: bool = True
    metrics_retention_hours: int = 168  # 1 week

    # Cost tracking
    cost_tracking_enabled: bool = True
    daily_budget: Optional[float] = None  # None = unlimited

    # Logging
    log_level: str = "INFO"
    structured_logging: bool = True

    # Error handling
    max_retries: int = 3
    retry_backoff_multiplier: float = 2.0
    circuit_breaker_threshold: int = 5
```

### Environment Variables

```bash
# .env file
MONITORING_ENABLED=true
COST_TRACKING_ENABLED=true
DAILY_BUDGET=10.00
LOG_LEVEL=INFO
STRUCTURED_LOGGING=true
```

---

## Best Practices

### 1. Performance Monitoring

‚úÖ **DO:**
- Monitor all production agents
- Set reasonable alert thresholds
- Review metrics regularly
- Export metrics for long-term analysis

‚ùå **DON'T:**
- Disable monitoring in production
- Ignore performance alerts
- Set thresholds too tight (causes alert fatigue)

### 2. Cost Management

‚úÖ **DO:**
- Set daily/monthly budgets
- Use GPT-4O-Mini for non-critical tasks
- Monitor cost trends
- Review optimization tips regularly

‚ùå **DON'T:**
- Use GPT-4 for everything
- Ignore budget alerts
- Skip cost optimization reviews

### 3. Error Handling

‚úÖ **DO:**
- Use retry logic for transient failures
- Implement circuit breakers for external services
- Log errors with context
- Handle errors gracefully

‚ùå **DON'T:**
- Retry indefinitely
- Ignore circuit breaker states
- Catch and swallow all exceptions
- Use bare except blocks

### 4. Explainability

‚úÖ **DO:**
- Add reasoning steps for important decisions
- Document alternatives considered
- Include confidence scores
- Note assumptions and limitations

‚ùå **DON'T:**
- Skip explanation for critical decisions
- Omit confidence information
- Ignore edge cases in explanations

---

## Testing

See `PHASE_10_TESTING.md` for comprehensive testing guide.

---

## Troubleshooting

### High Error Rates

1. Check error categories in dashboard
2. Review recent errors in monitoring API
3. Check if circuit breakers are open
4. Verify external service availability

### High Costs

1. Review cost breakdown by agent and model
2. Check optimization tips
3. Consider switching expensive models to GPT-4O-Mini
4. Review token usage patterns

### Performance Issues

1. Check average execution times
2. Identify slow agents
3. Review tool call counts
4. Check for timeout errors

### Monitoring Not Working

1. Verify monitoring routes are registered
2. Check backend logs for errors
3. Ensure frontend is connecting to correct API
4. Verify monitoring system initialization

---

## Future Enhancements

- [ ] Database persistence for long-term metrics
- [ ] Advanced analytics and ML-based predictions
- [ ] Custom dashboard creation
- [ ] Slack/email alert integration
- [ ] A/B testing framework for agents
- [ ] Automated performance tuning
- [ ] Real-time streaming metrics
- [ ] Multi-tenant cost isolation

---

## Support

For issues or questions:
1. Check this documentation
2. Review code comments
3. Check API endpoint documentation
4. Review error logs

---

**Last Updated:** 2025-01-14
**Version:** 1.0.0
**Status:** Production Ready ‚úÖ
